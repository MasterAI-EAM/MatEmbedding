{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17536dd1-427b-4c36-9efc-e287dc2c8dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     E:\\Anaconda3_2024\\envs\\pytorch\\lib\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random, json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6a06b-259c-4ce9-b235-76e6812d52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "os.environ[\"AZURE_OPENAI_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "# four models available: gpt-35-0125, gpt-4-0613, gpt-4-1106, gpt-4-32k-0613\n",
    "model = \"gpt-4-1106\"\n",
    "client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_KEY\"), \n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "with open('../data/zt_ori_84.txt', 'r') as f1:\n",
    "    lines = f1.readlines()\n",
    "    names = [line.strip().split('\\t')[0] for line in lines]\n",
    "    zt_scores = [line.strip().split('\\t')[1] for line in lines]\n",
    "# {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "# {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"}\n",
    "# print(response)\n",
    "# print(response.model_dump_json(indent=4))\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "def get_descriptions(prompt_material, file_name):\n",
    "    '''generate descriptions and save each description as a sentence list in a file.\n",
    "    :prompt_part param: the first half of the prompt\n",
    "    :file_name param: the name of the file to be saved'''\n",
    "    gpt4_descriptions85 = {}\n",
    "    # prompt = 'Give me one paragragh of general description of the key word thermoelectric.'\n",
    "    prompt = 'Give me several paragraghs of general description of the key word thermoelectric.'\n",
    "    response = client.chat.completions.create(model = model, messages = [{\"role\": \"user\", \"content\": prompt}])\n",
    "    gpt4_descriptions85['thermoelectric'] = sent_tokenize(response.choices[0].message.content)\n",
    "    for name in tqdm(names):\n",
    "        prompt =  prompt_material.format(name)\n",
    "        response = client.chat.completions.create(model = model, messages = [{\"role\": \"user\", \"content\": prompt}])\n",
    "        gpt4_descriptions85[name] = sent_tokenize(response.choices[0].message.content)\n",
    "    assert len([key for key in gpt4_descriptions85.keys() if key in names]) == 84\n",
    "    with open('../data/{}.txt'.format(file_name), 'w') as file:\n",
    "        file.write(json.dumps(gpt4_descriptions85))\n",
    "    return gpt4_descriptions85\n",
    "\n",
    "prompt_material = 'Give me one paragragh of general description of of the chemical compound {}.'\n",
    "file_name = 'gpt4_descriptions85_sents'\n",
    "# gpt4_descriptions85_sents = get_descriptions(prompt_material, file_name)\n",
    "\n",
    "prompt_material = 'Give me several paragraphs of general description of the chemical compound {}.'\n",
    "file_name = 'gpt4_descriptions85_more_sents'\n",
    "# gpt4_descriptions85_more_sents = get_descriptions(prompt_material, file_name)\n",
    "\n",
    "prompt_material = '''Please provide information about the material compound {}, including:\n",
    "General description: Chemical formula and composition, Crystal structure, Key physical properties (e.g., melting point, density, hardness), Typical synthesis methods, Common applications;\n",
    "Thermoelectric properties: Seebeck coefficient (S), Electrical conductivity (σ), Thermal conductivity (κ), Figure of merit (ZT), Optimal temperature range for thermoelectric performance, Strategies for enhancing thermoelectric properties (e.g., doping, nanostructuring); \n",
    "And please provide a concise summary focusing on the most important aspects of the material compound and its thermoelectric properties.'''\n",
    "file_name = 'gpt4_descriptions85_detailed'\n",
    "# gpt4_descriptions85_detailed = get_descriptions(prompt_material, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbfaa1df-a7c7-4e11-8333-65fbf6d8d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.964705882352941\n",
      "15.435294117647059\n",
      "25.188235294117646\n"
     ]
    }
   ],
   "source": [
    "# with open('../data/gpt4_descriptions85.txt', 'r') as file:\n",
    "#     gpt4_descriptions85 = json.loads(file.read())\n",
    "# gpt4_descriptions85_sents = {}\n",
    "# for key,value in gpt4_descriptions85.items():\n",
    "#     gpt4_descriptions85_sents[key] = sent_tokenize(value)   # nltk.tokenize.sent_tokenize(paragragh_string)\n",
    "# with open('../data/gpt4_descriptions85_sents.txt', 'w') as file:\n",
    "#     file.write(json.dumps(gpt4_descriptions85_sents))   # each description paragragh segmented into a list of sentences\n",
    "\n",
    "## average number of description sentences\n",
    "with open('../data/gpt4_descriptions85_sents.txt', 'r') as file:\n",
    "    gpt4_descriptions85_sents = json.loads(file.read())\n",
    "    num_sents = [len(value) for value in gpt4_descriptions85_sents.values() if type(value) == list]\n",
    "    print(np.mean(num_sents))\n",
    "\n",
    "with open('../data/gpt4_descriptions85_more_sents.txt', 'r') as file:\n",
    "    gpt4_descriptions85_more_sents = json.loads(file.read())\n",
    "    num_sents = [len(value) for value in gpt4_descriptions85_more_sents.values() if type(value) == list]\n",
    "    print(np.mean(num_sents))\n",
    "\n",
    "with open('../data/gpt4_descriptions85_detailed.txt', 'r') as file:\n",
    "    gpt4_descriptions85_detailed = json.loads(file.read())\n",
    "    num_sents = [len(value) for value in gpt4_descriptions85_detailed.values() if type(value) == list]\n",
    "    print(np.mean(num_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb4cb4-1274-4357-8047-9460ce718db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(file_name):\n",
    "    '''takes file_name as argument and returns the evaluation result spearman correlation.\n",
    "       :file_name params: context_sents85, rag_description85, gpt4_descriptions85, gpt4_descriptions85_sents'''\n",
    "    \n",
    "    file_path = '../data/{}.txt'.format(file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        dic = json.loads(file.read())\n",
    "    with open('../data/zt_ori_84.txt', 'r') as f1:\n",
    "        lines = f1.readlines()\n",
    "        names = [line.strip().split('\\t')[0] for line in lines]\n",
    "        zt_scores = [line.strip().split('\\t')[1] for line in lines]\n",
    "\n",
    "    model = SentenceTransformer('../outputs/SentMatBERT_MNR')\n",
    "    if type(dic['thermoelectric']) == list:\n",
    "        center_embedding = np.mean(model.encode(dic['thermoelectric']), axis=0)\n",
    "    elif type(dic['thermoelectric']) == str:\n",
    "        center_embedding = model.encode(dic['thermoelectric'])\n",
    "        \n",
    "    cos_sims = []\n",
    "    for name in tqdm(names):\n",
    "        if type(dic[name]) == list:\n",
    "            embedding = np.mean(model.encode(dic[name]), axis=0)\n",
    "        elif type(dic[name]) == str:\n",
    "            embedding = model.encode(dic[name])\n",
    "        cos_sim = 1-cosine(center_embedding, embedding)\n",
    "        cos_sims.append(cos_sim)\n",
    "        \n",
    "    corr, pvalue = stats.spearmanr(cos_sims, zt_scores)\n",
    "    return corr\n",
    "\n",
    "# print(evaluation('context_sents85'))   # 0.5924\n",
    "# print(evaluation('gpt4_descriptions85'))   # 0.4409\n",
    "print(evaluation('gpt4_descriptions85_sents'))   # 0.4968 (5 sents per material on average, general description)\n",
    "print(evaluation('gpt4_descriptions85_more_sents'))   # 0.5553 (15 sents per material on average, general description)\n",
    "print(evaluation('gpt4_descriptions85_detailed'))   # 0.0779 (25 sents per material on average, detailed description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f6a5c-1e1f-48e2-a684-0ba8686a7e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
